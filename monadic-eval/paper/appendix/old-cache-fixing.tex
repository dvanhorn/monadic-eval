
% Let us now take stock of what we've got.
% We use the following monad stack, which adds a ``cache'' component,
% which will be a finite map from states to sets of values:
% \begin{lstlisting}
% ¦ (ReaderT (FailT (StateT (NondetT (StateT+ ID)))))
% \end{lstlisting}
% 
% The ⸨StateT+⸩ monad transformer provides operations
% ⸨get-¢⸩ and ⸨update-¢›⸩ for getting and updating the
% cache, respectively. It joins its finite maps by union of the range
% when ⸨mplus⸩ is called, because it cannot defer to an
% underlying monoid as the outer ⸨StateT⸩ does with
% ⸨NondetT⸩.
% 
% Figure~\ref{f:ev-cache0} gives an ⸨ev⸩-wrapper that interposes
% itself on each recursive call to do the following steps:
% \begin{displayquote}
% Check if the current state is in the cache.  If it's in the cache, return all
% the results given in the cache.  If it's not, set the cache for the current
% state to the empty set, evaluate the expression, add the resulting value to the
% cache for the state, and return the result.
% \end{displayquote}
% 
% We can now define an evaluation function that mixes in ⸨ev-cache⸩:
% \begin{lstlisting}
% ¦ (define (eval e)
% ¦   (mrun ((fix (ev-cache ev)) e)))
% \end{lstlisting}
% 
% If we were to link this together with ⸨alloc@⸩ and ⸨δ@⸩, we'd obtain a concrete
% interpreter that either 1) produces the empty set because it encountered a
% loop, 2) produces a singleton result, or 3) diverges because it encounters an
% infinite set of states.  But if we were to link this together with ⸨alloc^@⸩
% and ⸨δ^@⸩, we'd obtain an abstract interpreter that is \emph{total}: it
% terminates on all inputs.
% 
% To see why this, observe that for a given program there only a finite set of
% possible caches.  We have already seen that there are a finite set of states
% and values, so it follows that there are only a finite set of maps from states
% to sets of values.  Now notice that on each recursive call, either the state is
% in the cache and it returns immediately, or the cache grows.  So programs
% simply cannot run forever because that would imply the cache would grow
% forever.
% 
% It should be easy to see that if evaluating a state ⸨ς⸩ requires recursively
% evaluating that same state, it will now produce the empty set since the cache
% will be updated to map ⸨ς⸩ to ⸨∅⸩ before proceeding to the sub-expressions.
% 
% We can now see that the caching abstract interpreter halts on programs that
% loop (for simplicity, the cache and store are omitted from the printed
% results):
% ℑ⁅
% ¦ > (rec f (λ (x) (f x)) (f 0))
% ℑ,
% ¦ '()
% ℑ⁆
% This accomplishes the goal of terminating on this example, and it even
% gives the right answer---the empty set---since this program produces
% no results.
% 
% It also works for recursive functions that terminate in the concrete,
% but have loops once abstracted:
% ℑ⁅
% ¦ > (rec fact (λ (n)
% ¦              (if0 n 1 (* n (fact (sub1 n)))))
% ¦     (fact 5))
% ℑ,
% ¦ '(N)
% ℑ⁆
% 
% It may seem we've accomplished our goal of making a sound and
% decidable abstract interpreter.  However this approach is broken in
% general: it is not sound in the presence of abstraction.  The problem
% here is that when the interpreter reaches ``the same'' state it has
% seen before, what we mean by ``the same'' in the presence of
% abstraction is subtle.  For example, imagine evaluating a function
% application of some function ⸨f⸩ to an abstract value
% ⸨'N⸩.  Suppose in evaluating this application we encounter
% another application of ⸨f⸩ to ⸨'N⸩.  Is it the same
% application?  Well, yes and no.  It is the same \emph{abstract} state,
% however the abstract state stands for a set of concrete states; in
% this case, the application of ⸨f⸩ to all numbers.  So there are
% states stood for in the abstraction that are equal \emph{and} not
% equal.  In other words, in the presence of abstraction, when a loop is
% detected, there \emph{may} be a loop in the concrete interpretation.
% Our naive loop detection set-up however is assuming there \emph{must}
% be a loop.
% 
% We can demonstrate the problem with a simple counter-example to
% soundness:
% ℑ⁅
% ¦ > (rec f (λ (x) 
% ¦            (if0 x 0 (if0 (f (sub1 x)) 2 3)))
% ¦      (f (add1 0)))
% ℑ,
% ¦ '(0)
% ℑ⁆
% 
% Concretely, this program returns ⸨2⸩, however with the
% combination of loop detection and abstraction, the abstract
% interpreter determines that this program produces ⸨0⸩, which is
% clearly unsound.
% \section{Fixing the Cache}\label{s:fixing-cache}
% 
% The basic problem with the caching solution of Section~\ref{s:cache} is that
% it cuts short the exploration of the program's behavior.  In the
% soundness counter-example, the inner call to ⸨f⸩ is present in
% the cache so neither branch of the conditional is taken; it is at this
% point of bottoming out that we determine ⸨f⸩ may return
% ⸨0⸩.  Of course, now we know that the conditional should have
% take the true branch since ⸨0⸩ could be returned, but it's too
% late: the program has terminated.
% 
% To restore soundness, what we need to do is somehow \emph{iterate} the
% interpreter so that we can re-explore the behavior knowing that
% ⸨f⸩ may produce ⸨0⸩.  A first thought may be to do a
% complete evaluation of the program, take the resulting cache, and then
% feed that in as the initial cache for a re-evaluation of the program.
% But there's an obvious problem... doing so would result in a cache hit
% and the saved results would be returned immediately without exploring
% any new behavior.
% 
% The real solution is that we want to use the prior evaluation's cache
% as a kind of co-inductive hypothesis: it's only when we detect a loop
% that we want to produce all of the results stored in the prior cache.
% This suggests a two-cache system in which the prior cache is only used
% when initializing the local cache.  In other words, we want to use the
% prior cache entry in the place of ⸨∅⸩.  When iterating the
% interpreter, we always start from an empty local cache and fall back
% on the prior cache results when initializing the cache entry before
% making a recursive call.  Since the prior cache is never written to,
% we can model the prior cache as a reader monad and add it to the
% stack:
% 
% The revised ⸨ev-cache@⸩ component is given in Figure~\ref{f:ev-cache}, which
% uses the ⸨ask-⊥⸩ operation to retreive the prior cache.  If the
% prior cache is empty, this code degenerates into exactly what was given in
% Figure~\ref{f:ev-cache0}.
% 
% We are left with two remaining problems; we need to figure out: 1) how
% to pipe the cache from one run of the interpreter into the next and 2)
% when to stop.  The answer to both is given in Figure~\ref{f:cache-fix}.
% 
% The ⸨fix-cache⸩ function takes a closed evaluator, just like ⸨eval-dead⸩ from
% Section~\ref{s:collecting}, i.e. something of the form ⸨(fix ev)⸩.  It
% iteratively runs the evaluator.  Each run of the evaluator resets the ``local''
% cache to empty and uses the cache of the previous run as it's fallback cache
% (initially it's empty).  The computation stops when a least fixed-point in the
% cache has been reached, that is, when running the evaluator with a prior gives
% no changes in the resulting cache.  At that point, the result is returned.
% 
% \begin{figure}
% \rfloat{⸨fix-cache@⸩}
% \begin{lstlisting}
% ¦ (define ((fix-cache eval) e)  
% ¦   (do ρ ← ask-env
% ¦       σ ← get-store
% ¦       ς ≔ (list e ρ σ)
% ¦       (mlfp (λ (Σ) (do (put-¢ ∅-map)
% ¦                        (put-store σ)
% ¦                        (local-⊥ Σ (eval e))
% ¦                        get-¢)))
% ¦       Σ ← get-¢
% ¦       (for/monad+ ([v×σ (Σ ς)])
% ¦         (do (put-store (cdr v×σ))
% ¦             (return (car v×σ))))))
% ¦ (define (mlfp f)
% ¦   (let loop ([x ∅-map])
% ¦     (do x′ ← (f x)
% ¦         (if (equal? x′ x)
% ¦             (return (void))
% ¦             (loop x′)))))
% \end{lstlisting}
% \caption{Finding Fixpoints in the Cache}
% \label{f:cache-fix}
% \end{figure}
% 
% With these peices in place, we can construct an interpreter as:
% \begin{lstlisting}
% ¦ (define (eval e)
% ¦   (mrun ((fix-cache (fix (ev-cache ev))) e)))
% \end{lstlisting}
% When linked with ⸨δ^⸩ and ⸨alloc^⸩, this interpreter is
% a computable---and we conjecture, sound---abstraction of the original
% definitional interpreter.  Note that the iterated evaluator always
% terminates: the cache resulting from each run of the evaluator
% contains \emph{at least} as much information as the prior cache, each
% run of the evaluator terminates, so the iterated evaluator terminates
% by the same principle as before: the cache monotonically grows and is
% finite in size.
% 
% We have thus achieved our goal and can confirm it gives
% the expected answers on the previous examples:
% ℑ⁅
% ¦ > (rec f (λ (x) (f x)) (f 0))
% ℑ,
% ¦ '()
% ℑ;
% ¦ > (rec fact (λ (n)
% ¦              (if0 n 1 (* n (fact (sub1 n)))))
% ¦     (fact 5))
% ℑ,
% ¦ '(N)
% ℑ;
% ¦ > (rec f (λ (x) 
% ¦            (if0 x 0 (if0 (f (sub1 x)) 2 3)))
% ¦      (f (add1 0)))
% ℑ,
% ¦ '(0 2 3)
% ℑ⁆
% Let us now take stock of what we've got.
