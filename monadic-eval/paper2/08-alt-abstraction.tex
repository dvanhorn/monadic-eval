\section{An Alternative Abstraction}\label{s:alt-abstraction}

\begin{figure}
\rfloat{⸨precise-δ@⸩}
\begin{lstlisting}
¦ (define (δ . ovs)
¦   (match ovs
¦     [`(add1 ,(? number? n))  (return (add1 n))]
¦     [`(+    ,(? number? n₁)
¦             ,(? number? n₂)) (return (+ n₁ n₂))]
¦     ...
¦     [`(add1 ,_) (return 'N)]
¦     [`(+ ,_ ,_) (return 'N)]
¦     ...
¦     ))
¦ (define (zero? v)
¦   (match v
¦     ['N (mplus (return #t) (return #f))]
¦     [_  (return (zero? v))]))
\end{lstlisting}
\figskip\rfloat{⸨store-crush@⸩}
\begin{lstlisting}
¦ (define (find a)
¦   (do σ ← get-store
¦       (for/monad+ ([v (σ a)])
¦         (return v))))
¦ (define (number*? n) (or (eq? 'N n) (number? n)))
¦ (define (crush v vs)
¦   (if (number*? v)
¦       (set-add 
¦         (for/set ([v* vs] #:unless (number*? v*)) 
¦           v*) 
¦         'N)
¦       (set-add vs v)))
¦ (define (ext a v)
¦   (update-store
¦    (λ (σ)
¦      (if (∈ a σ)
¦          (σ a (crush v (σ a)))
¦          (σ a (set v))))))
\end{lstlisting}
\caption{An Alternative Abstraction for Precise Primitives}
\label{f:pres-delta}
\end{figure}

In this section, we demonstrate how easy it is to experiment with
alternative abstraction strategies by swapping out components.  In
particular we look at an alternative abstraction of the interpretation
of primitive operations and store joins.

Figure~\ref{f:pres-delta} defines two new components:
⸨precise-δ@⸩ and ⸨store-crush@⸩.  The first is yet
another interpretation of the primitive operations.  The
distinguishing feature of this variant of ⸨δ⸩ is that it is
\emph{precision preserving}.  Unlike ⸨δ^@⸩, it does not
introduce abstraction, it merely propagates it.  So if you add two
concrete numbers together, you will get a concrete number.  But if you
add a concrete and abstract number, you will get an abstract number.

This interpretation of primitive operations clearly doesn't impose a
finite abstraction on it's own.  And if used in concert with the
⸨store-nd@⸩ implementation of the store, termination is not
guaranteed.  

The ⸨store-crush@⸩ implementation of the store is designed to
work with the precise version of ⸨δ⸩ by having a different
strategy for joining values into the store.  Using the precise
⸨δ⸩ and the standard store implementation, it's possible that
an infinite number of base values could be written into a single store
set.  What ⸨store-crush@⸩ does is widen base values to
⸨'N⸩ whevener there are multiple concrete numbers in a store
location.  Used together, this seems to ensure termination
since there is no way to write an infinite set of values in a
store location (and there are still a finite number of addresses due
to ⸨alloc^⸩).  This abstraction offers a
high-level of precision.  For example, ``straight-line'' arithmetic
operations are computed with full precision:
ℑ⁅
¦ > (* (+ 3 4) 9)
ℑ,
¦ '(63)
ℑ⁆
Even linear binding and arithmetic preserves precision:
ℑ⁅
¦ > ((λ (x) (* x x)) 5)
ℑ,
¦ '(25)
ℑ⁆
It's only when the approximation of binding structure comes in to
contact with base values that we see a loss in precision:
ℑ⁅
¦ > (let f (λ (x) x)
¦     (* (f 5) (f 5)))
ℑ,
'(N)
ℑ⁆
This combination of ⸨precise-δ@⸩ and ⸨store-crush@⸩ allows termination
for most programs, but still not all.
In the following example, ⸨id⸩ is eventually applied to a widened argument ⸨'N⸩,
which makes both conditional branches reachable.
The function returns ⸨0⸩ in the base case,
which is propagated to the recursive call and given to ⸨add1⸩,
which yields the concrete answer ⸨1⸩.
This results in a cycle where ⸨add1⸩ returns ⸨2⸩, ⸨3⸩, ⸨4⸩
when applied to ⸨1⸩, ⸨2⸩, ⸨3⸩, etc.
ℑ⁅
¦ > (rec id (λ (n)
¦             (if0 n 0 (add1 (id (sub1 n)))))
¦     (id 3))]
ℑ,
¦ timeout
ℑ⁆
To ensure termination for all programs, we assume all references
to primitive operations are $η$-expanded, so that store-allocations also take place
at primitive applications, ensuring widening at repeated bindings.
The above program terminates with this desugaring:
ℑ⁅
¦ > (rec id (λ (n)
¦             (if0 n
¦                  0
¦                  ((λ (i) (add1 i))
¦                   (id ((λ (j) (sub1 j)) n)))))
¦     (id 3))]
ℑ,
¦ '(0 N)
ℑ⁆


If this sets off worries about non-termination, try to construct a
program that computes an infinite set of numbers with a finite number
of variable bindings over the life of the program.  Hint: you won't be
able to.  (The second last example suggests an easy refinement to the
⸨store-crush@⸩ strategy: only widen when \emph{different} base
values are written to a shared location.  We leave this as an easy
exercise for the reader.)

Here we see one of the strengths of our approach.  This strategy
appears quite natural, and to the best of our knowledge, is novel.
It's hard to imagine how it could be formulated as, say, a
constraint-based flow analysis.
