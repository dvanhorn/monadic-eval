\section{An Alternative Abstraction}\label{s:alt-abstraction}

\begin{figure} %{-{
\rfloat{⸨precise-δ@⸩}
\begin{lstlisting}
¦ (define (δ o n₀ n₁)
¦   (match* (o n₀ n₁)
¦     [('+ (? num?) (? num?)) (return (+ n₀ n₁))]
¦     [('+ _        _       ) (return 'N)] ... ))
¦ (define (zero? v)
¦   (match v
¦     ['N (mplus (return #t) (return #f))]
¦     [_  (return (zero? v))]))
\end{lstlisting}
\figskip\rfloat{⸨store-crush@⸩}
\begin{lstlisting}
¦ (define (find a)
¦   (do σ ← get-store
¦       (for/monad+ ([v (σ a)]) (return v))))
¦ (define (crush v vs)
¦   (if (closure? v)
¦       (set-add vs v)
¦       (set-add (set-filter closure? vs) 'N)))
¦ (define (ext a v)
¦   (update-store (λ (σ) (if (∈ a σ)
¦                            (σ a (crush v (σ a)))
¦                            (σ a (set v))))))
\end{lstlisting}
\caption{An Alternative Abstraction for Precise Primitives}
\label{f:pres-delta}
\end{figure} %}-}

In this section, we demonstrate how easy it is to experiment with alternative
abstraction strategies by swapping out components.  In particular we look at an
alternative abstraction of primitive operations and store joins.

Figure~\ref{f:pres-delta} defines two new components: ⸨precise-δ@⸩ and
⸨store-crush@⸩.  The first is an alternative interpretation for primitive
operations that is \emph{precision preserving}.  Unlike ⸨δ^@⸩, it does not
introduce abstraction, it merely propagates it.  When two concrete
numbers are added together, the result will be a concrete number, but if either
number is abstract then the result is abstract.

This interpretation of primitive operations clearly doesn't impose a finite
abstraction on its own, because the state space for concrete numbers is
infinite. If ⸨precise-δ@⸩ is linked with the ⸨store-nd@⸩ implementation of the
store, termination is therefore not guaranteed.  

The ⸨store-crush@⸩ operations are designed to work with ⸨precise-δ@⸩ by
performing \emph{widening} when joining multiple concrete values into the
store. This abstraction offers a high-level of precision; for example,
``straight-line'' arithmetic operations are computed with full precision:
ℑ⁅
¦ > (* (+ 3 4) 9)
ℑ,
¦ '(63)
ℑ⁆
Even linear binding and arithmetic preserves precision:
ℑ⁅
¦ > ((λ (x) (* x x)) 5)
ℑ,
¦ '(25)
ℑ⁆
It's only when the approximation of binding structure comes in to
contact with base values that we see a loss in precision:
ℑ⁅
¦ > (let f (λ (x) x)
¦     (* (f 5) (f 5)))
ℑ,
'(N)
ℑ⁆
This combination of ⸨precise-δ@⸩ and ⸨store-crush@⸩ allows termination for most
programs, but still not all. In the following example, ⸨id⸩ is eventually
applied to a widened argument ⸨'N⸩, which makes both conditional branches
reachable. The function returns ⸨0⸩ in the base case, which is propagated to
the recursive call and added to ⸨1⸩, which yields the concrete answer ⸨1⸩.
This results in a cycle where the intermediate sum returns ⸨2⸩, ⸨3⸩, ⸨4⸩ when
applied to ⸨1⸩, ⸨2⸩, ⸨3⸩, etc.
ℑ⁅
¦ > (rec id (λ (n) (if0 n 0 (+ 1 (id (- n 1)))))
¦     (id 3))
ℑ,
¦ timeout
ℑ⁆
To ensure termination for all programs, we assume all references to
primitive operations are $η$-expanded, so that store-allocations also
take place at primitive applications, ensuring widening at repeated
bindings. In fact, all programs terminate when using ⸨precise-δ@⸩,
⸨store-crush@⸩ and «η»-expanded primitives, which means we have a
achieved a computable and uniquely precise abstract interpreter.

\begin{figure} %{-{
\rfloat{⸨symbolic-monad@⸩}
\begin{flalign*}
                  & 𝔥⸨(define-monad⸩
  & \\[\monadgobble]& ␣␣𝔥⸨(⸩\!\up{𝔥⸨ReaderT⸩}⸢env⸣\ 𝔥⸨(⸩\!\up{𝔥⸨FailT⸩}⸢errors⸣\ 𝔥⸨(⸩\!\up{𝔥⸨StateT⸩}⸢store⸣\ 𝔥⸨(⸩\!\up{𝔥⸨StateT⸩}⸢path⸣\ 𝔥⸨(⸩\!\up{𝔥⸨NondetT⸩}⸢mplus⸣\ 𝔥⸨ID))))))⸩
\end{flalign*}
\figskip\rfloat{⸨ev-symbolic@⸩}
\begin{lstlisting}
¦ (define (((ev-symbolic ev₀) ev) e)
¦   (match e [(sym x) (return x)]
¦            [e       ((ev₀ ev) e)]))
\end{lstlisting}
\figskip\rfloat{⸨δ-symbolic@⸩}
\begin{lstlisting}
¦ (define (δ o n₀ n₁)
¦   (match* (o n₀ n₁)
¦     [('/ n₀ n₁)
¦      (do z? ← (zero? n₁)
¦          (cond [z? fail]
¦                [(and (num? n₀) (num? n₁))
¦                 (return (/ n₀ n₁))]
¦                [else (return `(/ ,n₀ ,n₁))]))] ... ))
¦ (define (zero? v)
¦   (do φ ← get-path-cond
¦       (match v
¦         [(? num? n)             (return (= 0 n))]
¦         [v #:when (∈ v φ)       (return #t)]
¦         [v #:when (∈ `(¬ ,v) φ) (return #f)]
¦         [`(¬ ,v′) (do a ← (zero? v′) (return (not a)))]
¦         [v (mplus (do (refine v)       (return #t))
¦                   (do (refine `(¬ ,v)) (return #f)))])))
\end{lstlisting}
\caption{Symbolic Execution Variant}
\label{f:symbolic}
\end{figure} %}-}

Here we see one of the strengths of the extensible, definitional approach to
abstract interpreters. The combination of added precision and widening is
encoded quite naturally. In contrast, it's hard to imagine how such a
combination could be formulated as, say, a constraint-based flow analysis.
